{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8438c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340988d",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deacc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  []\n",
    "paths = [\n",
    "    'C:/Users/DELL/Downloads/gender/dataset1/train/man',\n",
    "    'C:/Users/DELL/Downloads/gender/dataset1/train/woman'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88a951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in paths:\n",
    "    folder_name = os.path.basename(i)\n",
    "    \n",
    "    # Iterate over the images in the subdirectory\n",
    "    for file_name in os.listdir(i):\n",
    "        image_path = os.path.join(i, file_name)\n",
    "        \n",
    "        if os.path.isfile(image_path):  # Only consider files\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # If the image was successfully loaded\n",
    "            if image is not None:\n",
    "                # Resize the grayscale image to 250X250 pixels\n",
    "                resized_image = cv2.resize(image, (250, 250))\n",
    "                \n",
    "                # Flatten the image and append each pixel as a separate feature along with the label to the dataset\n",
    "                flattened_image = resized_image.flatten().tolist()\n",
    "                dataset.append(flattened_image + [folder_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a67ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(dataset, columns=[f'pixel_{i+1}' for i in range(250*250)] + ['label'])\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "X = df.iloc[:, :-1] / 255\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "# Encode the labels with numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "y_series = pd.Series(Y_encoded, name='Target')\n",
    "\n",
    "# Concatenate 'X' (features) and 'y_series' (target variable) along columns (axis=1)\n",
    "df_encoded = pd.concat([X, y_series], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_series, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682537a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>pixel_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_62492</th>\n",
       "      <th>pixel_62493</th>\n",
       "      <th>pixel_62494</th>\n",
       "      <th>pixel_62495</th>\n",
       "      <th>pixel_62496</th>\n",
       "      <th>pixel_62497</th>\n",
       "      <th>pixel_62498</th>\n",
       "      <th>pixel_62499</th>\n",
       "      <th>pixel_62500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>160</td>\n",
       "      <td>169</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>168</td>\n",
       "      <td>160</td>\n",
       "      <td>154</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>171</td>\n",
       "      <td>188</td>\n",
       "      <td>205</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>180</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>173</td>\n",
       "      <td>171</td>\n",
       "      <td>169</td>\n",
       "      <td>167</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>70</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>77</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 62501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  pixel_8  \\\n",
       "0          63       64       65       66       68       70       71       73   \n",
       "1         247      247      248      248      248      248      248      248   \n",
       "2         153      153      160      169      178      177      168      160   \n",
       "3          22       20       18       16       14       11       15       20   \n",
       "4          82       82       81       80       78       77       73       70   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1595       15       16       17       19       22       24       24       24   \n",
       "1596       27       29       32       33       33       30       28       29   \n",
       "1597       70       39       27       47       60       59       48       51   \n",
       "1598       46       44       34       25       17       22       23       17   \n",
       "1599       32       32       33       33       33       32       32       31   \n",
       "\n",
       "      pixel_9  pixel_10  ...  pixel_62492  pixel_62493  pixel_62494  \\\n",
       "0          74        75  ...           19           19           19   \n",
       "1         248       248  ...           32           32           31   \n",
       "2         154       152  ...           21           21           20   \n",
       "3          27        31  ...           33           35           35   \n",
       "4          67        63  ...          157          156          156   \n",
       "...       ...       ...  ...          ...          ...          ...   \n",
       "1595       23        21  ...          182          180          178   \n",
       "1596       31        35  ...           24           19           21   \n",
       "1597       77        92  ...           99           99           99   \n",
       "1598       20        40  ...            5            7            8   \n",
       "1599       31        31  ...          172          175          186   \n",
       "\n",
       "      pixel_62495  pixel_62496  pixel_62497  pixel_62498  pixel_62499  \\\n",
       "0              19           19           19           19           20   \n",
       "1              30           30           31           33           34   \n",
       "2              20           20           20           21           21   \n",
       "3              36           37           37           37           37   \n",
       "4             156          171          188          205          216   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1595          177          176          173          171          169   \n",
       "1596           22           23           29           35           35   \n",
       "1597           98           97           96           95           94   \n",
       "1598           11           13           13            4            3   \n",
       "1599          185          183          184          185          185   \n",
       "\n",
       "      pixel_62500  label  \n",
       "0              20    man  \n",
       "1              36    man  \n",
       "2              21    man  \n",
       "3              38    man  \n",
       "4             216    man  \n",
       "...           ...    ...  \n",
       "1595          167  woman  \n",
       "1596           35  woman  \n",
       "1597           94  woman  \n",
       "1598            6  woman  \n",
       "1599          186  woman  \n",
       "\n",
       "[1600 rows x 62501 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb5eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg =  LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ae7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63096934",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6995f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(logreg, 'clmodel.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cfc78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "# Load the model from the saved file\n",
    "model = joblib.load('clmodel.pkl')\n",
    "# Function to preprocess an input image before making predictions\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    resized_image = cv2.resize(image, (250, 250))\n",
    "    flattened_image = resized_image.flatten().reshape(1, -1)\n",
    "    return flattened_image / 255.0\n",
    "\n",
    "# Function to make predictions using the loaded model\n",
    "def make_prediction(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "    predicted_class = prediction\n",
    "    return predicted_class\n",
    "test_folder = \"C:/Users/DELL/Downloads/gender/dataset1/test/man\"  # Replace with the path to your test folder\n",
    "\n",
    "for file_name in os.listdir(test_folder):\n",
    "    image_path = os.path.join(test_folder, file_name)\n",
    "    \n",
    "    if os.path.isfile(image_path):  # Only consider files\n",
    "        predicted_class = make_prediction(image_path)\n",
    "        if predicted_class == 0:\n",
    "            print(f\"Image: {file_name} | Predicted Class: MAN\")\n",
    "        if predicted_class == 1:\n",
    "            print(f\"Image: {file_name} | Predicted Class: WOMAN\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ab227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = SGDClassifier(loss = 'log_loss',max_iter=1000, tol=1e-3)\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d62f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdpred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a460f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915326c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.densify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, coef_init=None, intercept_init=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5f7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.predict_log_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ebbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,sgdpred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, sgdpred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svcClf = SVC(kernel=\"sigmoid\",gamma='auto', C=3,random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f225a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svcClf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "spred = svcClf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,spred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, spred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rclf = RandomForestClassifier(n_estimators=200,max_depth=3, random_state=0)\n",
    "rclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpred = rclf.predict(X_test)\n",
    "rpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,rpred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50828482",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, rpred)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
